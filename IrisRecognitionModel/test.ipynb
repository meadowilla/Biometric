{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hough_circle, hough_circle_peaks\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m equalize\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters.rank import equalize\n",
    "from skimage.morphology import disk\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def IrisLocalization(eye): # input is the eye image in grayscale\n",
    "    blured = cv2.bilateralFilter(eye, 9, 100, 100) # remove noise\n",
    "    Xp = blured.sum(axis=0).argmin() # index of the column with the least sum\n",
    "    Yp = blured.sum(axis=1).argmin() # index of the row with the least sum\n",
    "    x = blured[max(Yp - 60, 0):min(Yp + 60, 280), max(Xp - 60, 0):min(Xp + 60, 320)].sum(axis=0).argmin()\n",
    "    y = blured[max(Yp - 60, 0):min(Yp + 60, 280), max(Xp - 60, 0):min(Xp + 60, 320)].sum(axis=1).argmin()\n",
    "    Xp = max(Xp - 60, 0) + x\n",
    "    Yp = max(Yp - 60, 0) + y\n",
    "    if Xp >= 100 and Yp >= 80: # check if the pupil center is not too close to the edge\n",
    "        blur = cv2.GaussianBlur(eye[Yp - 60:Yp + 60, Xp - 60:Xp + 60], (5, 5), 0)\n",
    "        pupil_circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, dp=1.2, minDist=200, param1=200, param2=12, minRadius=15, maxRadius=80)\n",
    "        xp, yp, rp = np.round(pupil_circles[0][0]).astype(\"int\")\n",
    "        xp = Xp - 60 + xp\n",
    "        yp = Yp - 60 + yp\n",
    "    else:\n",
    "        pupil_circles = cv2.HoughCircles(blured, cv2.HOUGH_GRADIENT, 4, 280, minRadius=25, maxRadius=55, param2=51)\n",
    "        xp, yp, rp = np.round(pupil_circles[0][0]).astype(\"int\")\n",
    "\n",
    "    # Draw the circle on the original image\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(eye, cmap='gray')  # Display the grayscale image\n",
    "    # pupil_circle = plt.Circle((xp, yp), rp, color='red', fill=False, linewidth=2)  # Red circle\n",
    "    # ax.add_patch(pupil_circle)\n",
    "    # ax.plot(xp, yp, 'bo')  # Blue point at the center\n",
    "    # plt.title(\"Detected Pupil Circle\")\n",
    "    # plt.axis('off')  # Turn off axes for better visualization\n",
    "    # plt.show()\n",
    "\n",
    "    eye_copy = eye.copy()\n",
    "    rp = rp + 7 # slightly enlarge the pupil radius makes a better result\n",
    "    blured_copy = cv2.medianBlur(eye_copy, 11)\n",
    "    blured_copy = cv2.medianBlur(blured_copy, 11)\n",
    "    blured_copy = cv2.medianBlur(blured_copy, 11)\n",
    "    eye_edges = cv2.Canny(blured_copy, threshold1=15, threshold2=30, L2gradient=True) # edge detection\n",
    "\n",
    "    # Display the edge-detected image with pupil edges\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.title(\"With Pupil Edges\")\n",
    "    # plt.imshow(eye_edges, cmap='gray')\n",
    "\n",
    "    # Remove the edge of the pupil\n",
    "    eye_edges[:, xp - rp - 30:xp + rp + 30] = 0\n",
    "\n",
    "    # Display the edge-detected image without pupil edges\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.title(\"Without Pupil Edges\")\n",
    "    # plt.imshow(eye_edges, cmap='gray')\n",
    "    # plt.show()\n",
    "\n",
    "    hough_radii = np.arange(rp+45, 150, 2) # possible iris radii\n",
    "    hough_res = hough_circle(eye_edges, hough_radii) # hough transform to detect circles with different radii\n",
    "    accums, xi, yi, ri = hough_circle_peaks(hough_res, hough_radii, total_num_peaks=1) # find the mostt prominent circle (peak) to be the iris circle\n",
    "    iris = [] # iris circle\n",
    "    iris.extend(xi)\n",
    "    iris.extend(yi)\n",
    "    iris.extend(ri)\n",
    "    if ((iris[0] - xp) ** 2+(iris[1]-yp)**2) ** 0.5 > rp* 0.3: # using Euclidean distance to check if the iris circle is too far from the pupil, use the pupil circle instead\n",
    "        iris[0] = xp\n",
    "        iris[1] = yp\n",
    "    \n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(eye, cmap='gray')  # Display the grayscale image\n",
    "    # Draw the blue circle for the iris\n",
    "    # iris_circle = plt.Circle((iris[0], iris[1]), iris[2], color='blue', fill=False, linewidth=2)\n",
    "    # ax.add_patch(iris_circle)\n",
    "    # ax.plot(iris[0], iris[1], 'bo')  # Blue point at the iris center\n",
    "    # # Configure the plot\n",
    "    # plt.title(\"Without Pupil Edges\")\n",
    "    # plt.axis('off')  # Turn off axes for better visualization\n",
    "    # plt.show()\n",
    "\n",
    "    return np.array(iris), np.array([xp,yp,rp]) # return the iris and pupil circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IrisNormalization(image,inner_circle,outer_circle ):\n",
    "    localized_img=image\n",
    "    row=64\n",
    "    col=512\n",
    "    normalized_iris=np.zeros(shape=(64,512))\n",
    "    inner_y=inner_circle[0]  #height\n",
    "    inner_x=inner_circle[1] #width\n",
    "    outer_y=outer_circle[0]\n",
    "    outer_x=outer_circle[1]\n",
    "    angle=2.0*math.pi/col\n",
    "    # 1 row 512 col\n",
    "    inner_boundary_x = np.zeros(shape=(1,col)) # x coordinate of pupil boundary for each angle\n",
    "    inner_boundary_y = np.zeros(shape=(1,col)) # y coordinate of pupil boundary for each angle\n",
    "    outer_boundary_x = np.zeros(shape=(1,col)) # x coordinate of iris boundary for each angle\n",
    "    outer_boundary_y = np.zeros(shape=(1,col)) # y coordinate of iris boundary for each angle\n",
    "    for j in range(col):\n",
    "\n",
    "\n",
    "        inner_boundary_x[0][j]=inner_circle[0]+inner_circle[2]*math.cos(angle*(j))\n",
    "        inner_boundary_y[0][j]=inner_circle[1]+inner_circle[2]*math.sin(angle*(j))\n",
    "        \n",
    "        outer_boundary_x[0][j]=outer_circle[0]+outer_circle[2]*math.cos(angle*(j))\n",
    "        outer_boundary_y[0][j]=outer_circle[1]+outer_circle[2]*math.sin(angle*(j))\n",
    "        \n",
    "    for j in range (512):\n",
    "        for i in range (64):\n",
    "            normalized_iris[i][j]=localized_img[\n",
    "                min(int(int(inner_boundary_y[0][j])+(int(outer_boundary_y[0][j])-int(inner_boundary_y[0][j]))*(i/64.0)),localized_img.shape[0]-1)\n",
    "            ][\n",
    "                min(int(int(inner_boundary_x[0][j])+(int(outer_boundary_x[0][j])-int(inner_boundary_x[0][j]))*(i/64.0)),localized_img.shape[1]-1)\n",
    "            ]\n",
    "\n",
    "    res_image=255-normalized_iris\n",
    "\n",
    "    # plt.imshow(normalized_iris, cmap='gray')\n",
    "    # plt.title(\"Normalized Iris\")\n",
    "    # plt.show()\n",
    "    return res_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageEnhancement(normalized_iris):\n",
    "    row=64\n",
    "    col=512\n",
    "    normalized_iris = normalized_iris.astype(np.uint8)\n",
    "    enhanced_image=normalized_iris\n",
    "    enhanced_image = equalize(enhanced_image, disk(32))\n",
    "    roi = enhanced_image[0:48,:]\n",
    "    plt.imshow(roi, cmap='gray')\n",
    "    plt.title(\"Enhanced Iris\")\n",
    "    plt.show()\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter_bank(scales, orientations, ksize=31, sigma=2.24):\n",
    "    \"\"\"\n",
    "    Generates a bank of Gabor filters.\n",
    "    :param scales: Number of scales.\n",
    "    :param orientations: Number of orientations.\n",
    "    :param ksize: Size of the Gabor filter kernel.\n",
    "    :param sigma: Standard deviation of the Gaussian envelope.\n",
    "    :return: List of Gabor filters.\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    for scale in range(scales):\n",
    "        for orientation in range(orientations):\n",
    "            theta = orientation * np.pi / orientations\n",
    "            lambd = 4\n",
    "            gamma = 1\n",
    "            kernel_real = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi=0, ktype=cv2.CV_64F)\n",
    "            kernel_imag = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi=np.pi/2, ktype=cv2.CV_64F)\n",
    "            filters.append((kernel_real, kernel_imag))\n",
    "    \n",
    "    # Access the first Gabor filter (real and imaginary parts)\n",
    "    kernel_real = filters[0][0]\n",
    "    kernel_imag = filters[0][1]\n",
    "\n",
    "    # Visualize the first Gabor filter (real and imaginary parts)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(kernel_real, cmap='gray')\n",
    "    plt.title('Real Part of First Gabor Filter')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(kernel_imag, cmap='gray')\n",
    "    plt.title('Imaginary Part of First Gabor Filter')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n",
    "    return filters\n",
    "\n",
    "def apply_gabor_filters(image, filters):\n",
    "    \"\"\"\n",
    "    Apply a bank of Gabor filters to an image.\n",
    "    :param image: Input normalized iris image.\n",
    "    :param filters: List of Gabor filters.\n",
    "    :return: List of filtered responses (real and imaginary).\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for kernel_real, kernel_imag in filters:\n",
    "        # Apply the real part of the filter\n",
    "        response_real = cv2.filter2D(image, cv2.CV_64F, kernel_real)\n",
    "        # Apply the imaginary part of the filter\n",
    "        response_imag = cv2.filter2D(image, cv2.CV_64F, kernel_imag)\n",
    "        # Compute the magnitude of the response\n",
    "        magnitude = np.sqrt(response_real**2 + response_imag**2)\n",
    "        responses.append((response_real, response_imag, magnitude))\n",
    "    return responses\n",
    "\n",
    "def phase_quantization(responses):\n",
    "    \"\"\"\n",
    "    Quantize the phase of Gabor filter responses into 2-bit binary codes.\n",
    "    :param responses: List of Gabor filter responses (complex values).\n",
    "    :return: Binary feature vector (iris code).\n",
    "    \"\"\"\n",
    "    binary_code = []\n",
    "    for response in responses:\n",
    "        real = response[0]\n",
    "        imag = response[1]\n",
    "        phase = np.arctan2(imag, real)\n",
    "        quantized_phase = ((phase >= 0) & (phase < np.pi/2)) * 0b00 + \\\n",
    "                          ((phase >= np.pi/2) & (phase < np.pi)) * 0b01 + \\\n",
    "                          ((phase >= -np.pi) & (phase < -np.pi/2)) * 0b10 + \\\n",
    "                          ((phase >= -np.pi/2) & (phase < 0)) * 0b11\n",
    "        \n",
    "        # Convert each quantized value to 2 bits (binary representation)\n",
    "        binary_block = np.unpackbits(np.uint8(quantized_phase).reshape(-1, 1), axis=1)[:, -2:]\n",
    "        binary_code.append(binary_block.flatten())\n",
    "  \n",
    "    return np.hstack(binary_code)\n",
    "\n",
    "def FeatureExtraction(image, block_size, scales=1, orientations=4):\n",
    "    \"\"\"\n",
    "    Generate the binary feature vector (iris code) for an input image.\n",
    "    :param image: Normalized iris image.\n",
    "    :param block_size: Size of the blocks for pixel averaging.\n",
    "    :param scales: Number of scales for Gabor filters.\n",
    "    :param orientations: Number of orientations for Gabor filters.\n",
    "    :return: Binary feature vector (iris code).\n",
    "    \"\"\"\n",
    "    # Step 1: Divide the image into blocks and calculate block mean\n",
    "    h, w = image.shape\n",
    "    h_blocks, w_blocks = h // block_size, w // block_size\n",
    "    block_means = np.zeros((h_blocks, w_blocks))\n",
    "    for i in range(h_blocks):\n",
    "        for j in range(w_blocks):\n",
    "            block = image[i * block_size:(i + 1) * block_size, j * block_size:(j + 1) * block_size]\n",
    "            block_means[i, j] = np.mean(block)\n",
    "\n",
    "    # Step 2: Generate Gabor filter bank\n",
    "    filters = gabor_filter_bank(scales=scales, orientations=orientations)\n",
    "    # print(\"First filter: \", filters[0]) \n",
    "\n",
    "    # Step 3: Apply Gabor filters to the block means\n",
    "    responses = apply_gabor_filters(block_means, filters)\n",
    "\n",
    "    # Step 4: Quantize phase to generate binary iris code\n",
    "    iris_code = phase_quantization(responses)\n",
    "\n",
    "    return iris_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shift(code, shift):\n",
    "    \"\"\"\n",
    "    Circularly shift a binary code (list of 0s and 1s).\n",
    "    \n",
    "    Args:\n",
    "        code: List of binary values (e.g., [1, 0, 1, 0, 1]).\n",
    "        shift: Number of positions to shift. Positive for left, negative for right.\n",
    "    \n",
    "    Returns:\n",
    "        Shifted binary code.\n",
    "    \"\"\"\n",
    "    n = len(code)\n",
    "    shift = shift % n  # Handle shifts greater than the length of the code\n",
    "    return code[shift:] + code[:shift]\n",
    "\n",
    "def HammingDistance(code1, code2, mask1=None, mask2=None):\n",
    "    \"\"\"\n",
    "    Compute the Hamming distance between two iris codes.\n",
    "    :param code1: First binary iris code (numpy array).\n",
    "    :param code2: Second binary iris code (numpy array).\n",
    "    :param mask1: Mask for code1 (optional).\n",
    "    :param mask2: Mask for code2 (optional).\n",
    "    :return: Hamming distance.\n",
    "    \"\"\"\n",
    "    if mask1 is not None and mask2 is not None:\n",
    "        # Combine masks and exclude masked bits\n",
    "        combined_mask = mask1 & mask2\n",
    "        differing_bits = np.sum((code1 ^ code2) & ~combined_mask)\n",
    "        total_bits = np.sum(~combined_mask)\n",
    "    else:\n",
    "        # Without masks\n",
    "        differing_bits = np.sum(code1 ^ code2)\n",
    "        total_bits = code1.size\n",
    "    \n",
    "    if total_bits == 0:\n",
    "        return float('inf')  # Handle case where no bits are available for comparison\n",
    "    return differing_bits / total_bits\n",
    "\n",
    "def find_min_hamming_distance(reference_code, query_code):\n",
    "    \"\"\"\n",
    "    Find the minimum Hamming distance by circularly shifting the query code.\n",
    "    \n",
    "    Args:\n",
    "        reference_code: The reference binary code (list of 0s and 1s).\n",
    "        query_code: The query binary code (list of 0s and 1s).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing the minimum Hamming distance and the optimal shift value.\n",
    "    \"\"\"\n",
    "    n = len(query_code)\n",
    "    min_distance = float('inf')\n",
    "    best_shift = 0\n",
    "    \n",
    "    for shift in range(n):\n",
    "        shifted_code = circular_shift(query_code, shift)\n",
    "        reference_code = np.array(reference_code)\n",
    "        shifted_code = np.array(shifted_code)\n",
    "        distance = HammingDistance(reference_code, shifted_code)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_shift = shift\n",
    "    \n",
    "    return min_distance, best_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image processing and feature extraction takes 14 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 138\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage processing and feature extraction takes \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m((endtime_1\u001b[38;5;241m-\u001b[39mstarttime)\u001b[38;5;241m.\u001b[39mseconds) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m''' med = 0\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03mfor i in range(1, 26):\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    filespath = rootpath + str(i).zfill(3)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03mprint('feature matching and performance evaluation takes '+ str((endtime_2-starttime).seconds) + ' seconds')\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m \u001b[43mPE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_CRR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m PE\u001b[38;5;241m.\u001b[39mperformance_evaluation(train_features, train_classes, test_features, test_classes)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m#thresholds_2=[0.74,0.76,0.78]\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# PE.FMR_conf(fmrs_mean,fmrs_l,fmrs_u,fnmrs_mean,fnmrs_l,fnmrs_u)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# PE.FNMR_conf(fmrs_mean,fmrs_l,fmrs_u,fnmrs_mean,fnmrs_l,fnmrs_u)\u001b[39;00m\n",
      "File \u001b[1;32md:\\at school\\2024.1\\Biometric Authentication System\\Project\\Biometric\\IrisRecognitionModel\\PerformanceEvaluation.py:12\u001b[0m, in \u001b[0;36mtable_CRR\u001b[1;34m(train_features, train_classes, test_features, test_classes)\u001b[0m\n\u001b[0;32m     10\u001b[0m L2_1,_,_ \u001b[38;5;241m=\u001b[39m IrisMatching(train_features, train_classes, test_features, test_classes, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     11\u001b[0m C_1,distsm,distsn \u001b[38;5;241m=\u001b[39m IrisMatching(train_features, train_classes, test_features, test_classes, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m L1_2,L2_2,C_2\u001b[38;5;241m=\u001b[39m\u001b[43mIrisMatchingRed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrect recognition rate (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate([[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL1 distance measure\u001b[39m\u001b[38;5;124m'\u001b[39m,L1_1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m ,L1_2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m],[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2 distance measure\u001b[39m\u001b[38;5;124m'\u001b[39m, L2_1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,L2_2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCosine similarity measure\u001b[39m\u001b[38;5;124m'\u001b[39m, C_1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,C_2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m]], headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilartiy measure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal feature set\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduced feature set\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[1;32md:\\at school\\2024.1\\Biometric Authentication System\\Project\\Biometric\\IrisRecognitionModel\\IrisMatching.py:73\u001b[0m, in \u001b[0;36mIrisMatchingRed\u001b[1;34m(train_features, train_classes, test_features, test_classes, n)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m108\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m323\u001b[39m:\n\u001b[0;32m     72\u001b[0m     lle \u001b[38;5;241m=\u001b[39m LocallyLinearEmbedding(n_neighbors\u001b[38;5;241m=\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,n_components\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m---> 73\u001b[0m     \u001b[43mlle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     train_redfeatures \u001b[38;5;241m=\u001b[39m lle\u001b[38;5;241m.\u001b[39mtransform(train_features)\n\u001b[0;32m     75\u001b[0m     test_redfeatures \u001b[38;5;241m=\u001b[39m lle\u001b[38;5;241m.\u001b[39mtransform(test_features)\n",
      "File \u001b[1;32md:\\at school\\2024.1\\Biometric Authentication System\\Project\\Biometric\\IrisRecognitionModel\\myenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\at school\\2024.1\\Biometric Authentication System\\Project\\Biometric\\IrisRecognitionModel\\myenv\\Lib\\site-packages\\sklearn\\manifold\\_locally_linear.py:827\u001b[0m, in \u001b[0;36mLocallyLinearEmbedding.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the embedding vectors for data X.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \n\u001b[0;32m    814\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;124;03m        Fitted `LocallyLinearEmbedding` class instance.\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\at school\\2024.1\\Biometric Authentication System\\Project\\Biometric\\IrisRecognitionModel\\myenv\\Lib\\site-packages\\sklearn\\manifold\\_locally_linear.py:794\u001b[0m, in \u001b[0;36mLocallyLinearEmbedding._fit_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    792\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnbrs_\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m--> 794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreconstruction_error_ \u001b[38;5;241m=\u001b[39m \u001b[43m_locally_linear_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbrs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43meigen_solver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigen_solver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhessian_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhessian_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodified_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodified_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\at school\\2024.1\\Biometric Authentication System\\Project\\Biometric\\IrisRecognitionModel\\myenv\\Lib\\site-packages\\sklearn\\manifold\\_locally_linear.py:226\u001b[0m, in \u001b[0;36m_locally_linear_embedding\u001b[1;34m(X, n_neighbors, n_components, reg, eigen_solver, tol, max_iter, method, hessian_tol, modified_tol, random_state, n_jobs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput dimension must be less than or equal to input dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m     )\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N:\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples,  but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;241m%\u001b[39m (N, n_neighbors)\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    231\u001b[0m M_sparse \u001b[38;5;241m=\u001b[39m eigen_solver \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m M_container_constructor \u001b[38;5;241m=\u001b[39m lil_matrix \u001b[38;5;28;01mif\u001b[39;00m M_sparse \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 201"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PerformanceEvaluation as PE\n",
    "\n",
    "# Define the root path to the dataset and normalizedpath to save the normalized images\n",
    "rootpath = \"D:/at school/2024.1/Biometric Authentication System/Project/Biometric/IrisRecognitionModel/CASIA Iris Image Database (version 1.0)/\"\n",
    "normalizedpath = \"D:/at school/2024.1/Biometric Authentication System/Project/Biometric/IrisRecognitionModel/Normalized Images/\"\n",
    "iriscodepath = \"D:/at school/2024.1/Biometric Authentication System/Project/Biometric/IrisRecognitionModel/Iris Codes/\"\n",
    "\n",
    "# Create the new folder if it doesn't exist\n",
    "if not os.path.exists(normalizedpath):\n",
    "    os.makedirs(normalizedpath)\n",
    "if not os.path.exists(iriscodepath):\n",
    "    os.makedirs(iriscodepath)\n",
    "\n",
    "# Initialize arrays to hold training and testing features and classes\n",
    "train_features = np.zeros((9,1024)) # there are 324 training images, each represented by a 1536-dimensional feature vector\n",
    "train_classes = np.zeros(9, dtype = np.uint8) \n",
    "test_features = np.zeros((12,1024)) # 108 subjects * 4 images\n",
    "test_classes = np.zeros(12, dtype = np.uint8)\n",
    "\n",
    "# Record the start time of the process\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# Loop through each subject in the dataset\n",
    "for i in range(1, 26):\n",
    "    # Define paths for training and testing images for the current subject\n",
    "    filespath = rootpath + str(i).zfill(3)\n",
    "    normalizedFilesPath = normalizedpath + str(i).zfill(3)\n",
    "    iriscodeFilesPath = iriscodepath + str(i).zfill(3)\n",
    "    if not os.path.exists(normalizedFilesPath):\n",
    "        os.makedirs(normalizedFilesPath)\n",
    "    if not os.path.exists(iriscodeFilesPath):\n",
    "        os.makedirs(iriscodeFilesPath)\n",
    "\n",
    "    trainpath = filespath + \"/1/\"\n",
    "    testpath = filespath + \"/2/\"\n",
    "    normalizedTrainPath = normalizedFilesPath + \"/1/\"\n",
    "    normalizedTestPath = normalizedFilesPath + \"/2/\"\n",
    "    iriscodeTrainPath = iriscodeFilesPath + \"/1/\"\n",
    "    iriscodeTestPath = iriscodeFilesPath + \"/2/\"\n",
    "    if not os.path.exists(normalizedTrainPath):\n",
    "        os.makedirs(normalizedTrainPath)\n",
    "    if not os.path.exists(normalizedTestPath):\n",
    "        os.makedirs(normalizedTestPath)\n",
    "    if not os.path.exists(iriscodeTrainPath):\n",
    "        os.makedirs(iriscodeTrainPath)\n",
    "    if not os.path.exists(iriscodeTestPath):\n",
    "        os.makedirs(iriscodeTestPath)\n",
    "\n",
    "    '''\n",
    "    # Loop through each training image for the current subject\n",
    "    for j in range(1,4):\n",
    "        # Construct the file path for the current training image\n",
    "        irispath = trainpath + str(i).zfill(3) + \"_1_\" + str(j) + \".bmp\"\n",
    "\n",
    "        eye = cv2.imread(irispath, cv2.IMREAD_GRAYSCALE)\n",
    "        iris, pupil = IrisLocalization(eye)\n",
    "        normalized = IrisNormalization(eye, pupil, iris)\n",
    "        cv2.imwrite(os.path.join(normalizedTrainPath, str(i).zfill(3) + \"_1_\" + str(j) + \".png\"), normalized)\n",
    "        # ROI = ImageEnhancement(normalized)\n",
    "        # cv2.imwrite(os.path.join(normalizedTrainPath, str(i).zfill(3) + \"_1_\" + str(j) + \".png\"), ROI)\n",
    "\n",
    "        block_size = 16\n",
    "        train_iris_code = FeatureExtraction(normalized, block_size)\n",
    "        np.savetxt(os.path.join(iriscodeTrainPath, str(i).zfill(3) + \"_1_\" + str(j) + \".txt\"), train_iris_code, fmt='%d')\n",
    "\n",
    "    for k in range(1,5):\n",
    "        # Construct the file path for the current training image\n",
    "        irispath = testpath + str(i).zfill(3) + \"_2_\" + str(k) + \".bmp\"\n",
    "\n",
    "        eye = cv2.imread(irispath, cv2.IMREAD_GRAYSCALE)\n",
    "        iris, pupil = IrisLocalization(eye)\n",
    "        normalized = IrisNormalization(eye, pupil, iris)\n",
    "        cv2.imwrite(os.path.join(normalizedTestPath, str(i).zfill(3) + \"_2_\" + str(k) + \".png\"), normalized)\n",
    "\n",
    "        block_size = 16\n",
    "        test_iris_code = FeatureExtraction(normalized, block_size)\n",
    "        np.savetxt(os.path.join(iriscodeTestPath, str(i).zfill(3) + \"_2_\" + str(k) + \".txt\"), test_iris_code, fmt='%d')\n",
    "    '''\n",
    "\n",
    "    for j in range(1,4):\n",
    "        # Construct the file path for the current training image\n",
    "        irispath = trainpath + str(i).zfill(3) + \"_1_\" + str(j) + \".bmp\"\n",
    "\n",
    "        eye = cv2.imread(irispath, cv2.IMREAD_GRAYSCALE)\n",
    "        iris, pupil = IrisLocalization(eye)\n",
    "        normalized = IrisNormalization(eye, pupil, iris)\n",
    "        train_features[(i-1)*3+j-1, :] = FeatureExtraction(normalized, 16)\n",
    "        train_classes[(i-1)*3+j-1] = i\n",
    "    \n",
    "    for k in range(1,5):\n",
    "        # Construct the file path for the current training image\n",
    "        irispath = testpath + str(i).zfill(3) + \"_2_\" + str(k) + \".bmp\"\n",
    "\n",
    "        eye = cv2.imread(irispath, cv2.IMREAD_GRAYSCALE)\n",
    "        iris, pupil = IrisLocalization(eye)\n",
    "        normalized = IrisNormalization(eye, pupil, iris)\n",
    "        test_features[(i-1)*4+k-1, :] = FeatureExtraction(normalized, 16)\n",
    "        test_classes[(i-1)*4+k-1] = i\n",
    "\n",
    "    # train_tmp = np.loadtxt(iriscodeTestPath + str(i).zfill(3) + \"_2_1.txt\", dtype=int)\n",
    "    # test_tmp = np.loadtxt(iriscodeTestPath + str(i).zfill(3) + \"_2_2.txt\", dtype=int)\n",
    "    # min_distance, best_shift = find_min_hamming_distance(train_tmp.tolist(), test_tmp.tolist())\n",
    "    # print(f\"Test {i}: min_distance = {min_distance}, best_shift = {best_shift}\")\n",
    "\n",
    "endtime_1 = datetime.datetime.now()\n",
    "print('image processing and feature extraction takes ' + str((endtime_1-starttime).seconds) + ' seconds')\n",
    "\n",
    "''' med = 0\n",
    "for i in range(1, 26):\n",
    "    filespath = rootpath + str(i).zfill(3)\n",
    "    normalizedFilesPath = normalizedpath + str(i).zfill(3)\n",
    "    iriscodeFilesPath = iriscodepath + str(i).zfill(3)\n",
    "\n",
    "    trainpath = filespath + \"/1/\"\n",
    "    testpath = filespath + \"/2/\"\n",
    "    normalizedTrainPath = normalizedFilesPath + \"/1/\"\n",
    "    normalizedTestPath = normalizedFilesPath + \"/2/\"\n",
    "    iriscodeTrainPath = iriscodeFilesPath + \"/1/\"\n",
    "    iriscodeTestPath = iriscodeFilesPath + \"/2/\"\n",
    "\n",
    "    count = 0\n",
    "    for j in range(1, 4):\n",
    "        for k in range (1, 5):\n",
    "            train_tmp = np.loadtxt(iriscodeTrainPath + str(i).zfill(3) + \"_1_\" + str(j) + \".txt\", dtype=int)\n",
    "            test_tmp = np.loadtxt(iriscodeTestPath + str(i).zfill(3) + \"_2_\" + str(k) + \".txt\", dtype=int)\n",
    "            min_distance, best_shift = find_min_hamming_distance(train_tmp.tolist(), test_tmp.tolist())\n",
    "            if (min_distance <= 0.35):\n",
    "                count += 1\n",
    "    print(f\"Test {i}: \", count /12 *100, \"%\")\n",
    "    med = med + count\n",
    "\n",
    "print(\"overall: \", med /25 /12 *100, \"%\")\n",
    "endtime_2 = datetime.datetime.now()\n",
    "print('feature matching and performance evaluation takes '+ str((endtime_2-starttime).seconds) + ' seconds')\n",
    "'''\n",
    "\n",
    "PE.table_CRR(train_features, train_classes, test_features, test_classes)\n",
    "PE.performance_evaluation(train_features, train_classes, test_features, test_classes)\n",
    "#thresholds_2=[0.74,0.76,0.78]\n",
    "\n",
    "\n",
    "# # this part is for bootsrap\n",
    "# starttime = datetime.datetime.now() \n",
    "# thresholds_3=np.arange(0.6,0.9,0.02)\n",
    "# times = 10 #running 100 times takes about 1 to 2 hours\n",
    "# total_fmrs, total_fnmrs, crr_mean, crr_u, crr_l = IM.IrisMatchingBootstrap(train_features, train_classes, test_features, test_classes,times,thresholds_3)\n",
    "# fmrs_mean,fmrs_l,fmrs_u,fnmrs_mean,fnmrs_l,fnmrs_u = IM.calcROCBootstrap(total_fmrs, total_fnmrs)\n",
    "\n",
    "# endtime = datetime.datetime.now()\n",
    "\n",
    "# print('Bootsrap takes '+str((endtime-starttime).seconds) + ' seconds')\n",
    "\n",
    "# fmrs_mean *= 100  #use for percent(%)\n",
    "# fmrs_l *= 100\n",
    "# fmrs_u *= 100\n",
    "# fnmrs_mean *= 100\n",
    "# fnmrs_l *= 100\n",
    "# fnmrs_u *= 100\n",
    "# PE.FM_FNM_table(fmrs_mean,fmrs_l,fmrs_u,fnmrs_mean,fnmrs_l,fnmrs_u, thresholds_3)\n",
    "# PE.FMR_conf(fmrs_mean,fmrs_l,fmrs_u,fnmrs_mean,fnmrs_l,fnmrs_u)\n",
    "# PE.FNMR_conf(fmrs_mean,fmrs_l,fmrs_u,fnmrs_mean,fnmrs_l,fnmrs_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Authenticate(iris_code, stored_templates, threshold=0.32):\n",
    "    for template in stored_templates:\n",
    "        distance = HammingDistance(iris_code, template)\n",
    "        if distance < threshold:\n",
    "            return True  # Authentication successful\n",
    "    return False  # Authentication failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucess = Authenticate(iris_code_3, [iris_code_1, iris_code_2])\n",
    "# print(f\"Authentication: {sucess}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
