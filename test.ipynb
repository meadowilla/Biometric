{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters.rank import equalize\n",
    "from skimage.morphology import disk\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def IrisLocalization(eye): # input is the eye image in grayscale\n",
    "    blured = cv2.bilateralFilter(eye, 9, 100, 100) # remove noise\n",
    "    Xp = blured.sum(axis=0).argmin() # index of the column with the least sum\n",
    "    Yp = blured.sum(axis=1).argmin() # index of the row with the least sum\n",
    "    x = blured[max(Yp - 60, 0):min(Yp + 60, 280), max(Xp - 60, 0):min(Xp + 60, 320)].sum(axis=0).argmin()\n",
    "    y = blured[max(Yp - 60, 0):min(Yp + 60, 280), max(Xp - 60, 0):min(Xp + 60, 320)].sum(axis=1).argmin()\n",
    "    Xp = max(Xp - 60, 0) + x\n",
    "    Yp = max(Yp - 60, 0) + y\n",
    "    if Xp >= 100 and Yp >= 80: # check if the pupil center is not too close to the edge\n",
    "        blur = cv2.GaussianBlur(eye[Yp - 60:Yp + 60, Xp - 60:Xp + 60], (5, 5), 0)\n",
    "        pupil_circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, dp=1.2, minDist=200, param1=200, param2=12, minRadius=15, maxRadius=80)\n",
    "        xp, yp, rp = np.round(pupil_circles[0][0]).astype(\"int\")\n",
    "        xp = Xp - 60 + xp\n",
    "        yp = Yp - 60 + yp\n",
    "    else:\n",
    "        pupil_circles = cv2.HoughCircles(blured, cv2.HOUGH_GRADIENT, 4, 280, minRadius=25, maxRadius=55, param2=51)\n",
    "        xp, yp, rp = np.round(pupil_circles[0][0]).astype(\"int\")\n",
    "\n",
    "    # Draw the circle on the original image\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(eye, cmap='gray')  # Display the grayscale image\n",
    "    # pupil_circle = plt.Circle((xp, yp), rp, color='red', fill=False, linewidth=2)  # Red circle\n",
    "    # ax.add_patch(pupil_circle)\n",
    "    # ax.plot(xp, yp, 'bo')  # Blue point at the center\n",
    "    # plt.title(\"Detected Pupil Circle\")\n",
    "    # plt.axis('off')  # Turn off axes for better visualization\n",
    "    # plt.show()\n",
    "\n",
    "    eye_copy = eye.copy()\n",
    "    rp = rp + 7 # slightly enlarge the pupil radius makes a better result\n",
    "    blured_copy = cv2.medianBlur(eye_copy, 11)\n",
    "    blured_copy = cv2.medianBlur(blured_copy, 11)\n",
    "    blured_copy = cv2.medianBlur(blured_copy, 11)\n",
    "    eye_edges = cv2.Canny(blured_copy, threshold1=15, threshold2=30, L2gradient=True) # edge detection\n",
    "\n",
    "    # Display the edge-detected image with pupil edges\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.title(\"With Pupil Edges\")\n",
    "    # plt.imshow(eye_edges, cmap='gray')\n",
    "\n",
    "    # Remove the edge of the pupil\n",
    "    eye_edges[:, xp - rp - 30:xp + rp + 30] = 0\n",
    "\n",
    "    # Display the edge-detected image without pupil edges\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.title(\"Without Pupil Edges\")\n",
    "    # plt.imshow(eye_edges, cmap='gray')\n",
    "    # plt.show()\n",
    "\n",
    "    hough_radii = np.arange(rp+45, 150, 2) # possible iris radii\n",
    "    hough_res = hough_circle(eye_edges, hough_radii) # hough transform to detect circles with different radii\n",
    "    accums, xi, yi, ri = hough_circle_peaks(hough_res, hough_radii, total_num_peaks=1) # find the mostt prominent circle (peak) to be the iris circle\n",
    "    iris = [] # iris circle\n",
    "    iris.extend(xi)\n",
    "    iris.extend(yi)\n",
    "    iris.extend(ri)\n",
    "    if ((iris[0] - xp) ** 2+(iris[1]-yp)**2) ** 0.5 > rp* 0.3: # using Euclidean distance to check if the iris circle is too far from the pupil, use the pupil circle instead\n",
    "        iris[0] = xp\n",
    "        iris[1] = yp\n",
    "    \n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(eye, cmap='gray')  # Display the grayscale image\n",
    "    # Draw the blue circle for the iris\n",
    "    # iris_circle = plt.Circle((iris[0], iris[1]), iris[2], color='blue', fill=False, linewidth=2)\n",
    "    # ax.add_patch(iris_circle)\n",
    "    # ax.plot(iris[0], iris[1], 'bo')  # Blue point at the iris center\n",
    "    # # Configure the plot\n",
    "    # plt.title(\"Without Pupil Edges\")\n",
    "    # plt.axis('off')  # Turn off axes for better visualization\n",
    "    # plt.show()\n",
    "\n",
    "    return np.array(iris), np.array([xp,yp,rp]) # return the iris and pupil circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IrisNormalization(image,inner_circle,outer_circle ):\n",
    "    localized_img=image\n",
    "    row=64\n",
    "    col=512\n",
    "    normalized_iris=np.zeros(shape=(64,512))\n",
    "    inner_y=inner_circle[0]  #height\n",
    "    inner_x=inner_circle[1] #width\n",
    "    outer_y=outer_circle[0]\n",
    "    outer_x=outer_circle[1]\n",
    "    angle=2.0*math.pi/col\n",
    "    # 1 row 512 col\n",
    "    inner_boundary_x = np.zeros(shape=(1,col)) # x coordinate of pupil boundary for each angle\n",
    "    inner_boundary_y = np.zeros(shape=(1,col)) # y coordinate of pupil boundary for each angle\n",
    "    outer_boundary_x = np.zeros(shape=(1,col)) # x coordinate of iris boundary for each angle\n",
    "    outer_boundary_y = np.zeros(shape=(1,col)) # y coordinate of iris boundary for each angle\n",
    "    for j in range(col):\n",
    "\n",
    "\n",
    "        inner_boundary_x[0][j]=inner_circle[0]+inner_circle[2]*math.cos(angle*(j))\n",
    "        inner_boundary_y[0][j]=inner_circle[1]+inner_circle[2]*math.sin(angle*(j))\n",
    "        \n",
    "        outer_boundary_x[0][j]=outer_circle[0]+outer_circle[2]*math.cos(angle*(j))\n",
    "        outer_boundary_y[0][j]=outer_circle[1]+outer_circle[2]*math.sin(angle*(j))\n",
    "        \n",
    "    for j in range (512):\n",
    "        for i in range (64):\n",
    "            normalized_iris[i][j]=localized_img[\n",
    "                min(int(int(inner_boundary_y[0][j])+(int(outer_boundary_y[0][j])-int(inner_boundary_y[0][j]))*(i/64.0)),localized_img.shape[0]-1)\n",
    "            ][\n",
    "                min(int(int(inner_boundary_x[0][j])+(int(outer_boundary_x[0][j])-int(inner_boundary_x[0][j]))*(i/64.0)),localized_img.shape[1]-1)\n",
    "            ]\n",
    "\n",
    "    res_image=255-normalized_iris\n",
    "\n",
    "    # plt.imshow(normalized_iris, cmap='gray')\n",
    "    # plt.title(\"Normalized Iris\")\n",
    "    # plt.show()\n",
    "    return res_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageEnhancement(normalized_iris):\n",
    "    row=64\n",
    "    col=512\n",
    "    normalized_iris = normalized_iris.astype(np.uint8)\n",
    "    enhanced_image=normalized_iris\n",
    "    enhanced_image = equalize(enhanced_image, disk(32))\n",
    "    roi = enhanced_image[0:48,:]\n",
    "    plt.imshow(roi, cmap='gray')\n",
    "    plt.title(\"Enhanced Iris\")\n",
    "    plt.show()\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter_bank(scales, orientations, ksize=31, sigma=2.24):\n",
    "    \"\"\"\n",
    "    Generates a bank of Gabor filters.\n",
    "    :param scales: Number of scales.\n",
    "    :param orientations: Number of orientations.\n",
    "    :param ksize: Size of the Gabor filter kernel.\n",
    "    :param sigma: Standard deviation of the Gaussian envelope.\n",
    "    :return: List of Gabor filters.\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    for scale in range(scales):\n",
    "        for orientation in range(orientations):\n",
    "            theta = orientation * np.pi / orientations\n",
    "            lambd = 4\n",
    "            gamma = 1\n",
    "            kernel_real = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi=0, ktype=cv2.CV_64F)\n",
    "            kernel_imag = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi=np.pi/2, ktype=cv2.CV_64F)\n",
    "            filters.append((kernel_real, kernel_imag))\n",
    "    \n",
    "    # Access the first Gabor filter (real and imaginary parts)\n",
    "    kernel_real = filters[0][0]\n",
    "    kernel_imag = filters[0][1]\n",
    "\n",
    "    # Visualize the first Gabor filter (real and imaginary parts)\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.imshow(kernel_real, cmap='gray')\n",
    "    # plt.title('Real Part of First Gabor Filter')\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.imshow(kernel_imag, cmap='gray')\n",
    "    # plt.title('Imaginary Part of First Gabor Filter')\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # plt.show()\n",
    "    return filters\n",
    "\n",
    "def apply_gabor_filters(image, filters):\n",
    "    \"\"\"\n",
    "    Apply a bank of Gabor filters to an image.\n",
    "    :param image: Input normalized iris image.\n",
    "    :param filters: List of Gabor filters.\n",
    "    :return: List of filtered responses (real and imaginary).\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    for kernel_real, kernel_imag in filters:\n",
    "        # Apply the real part of the filter\n",
    "        response_real = cv2.filter2D(image, cv2.CV_64F, kernel_real)\n",
    "        # Apply the imaginary part of the filter\n",
    "        response_imag = cv2.filter2D(image, cv2.CV_64F, kernel_imag)\n",
    "        # Compute the magnitude of the response\n",
    "        magnitude = np.sqrt(response_real**2 + response_imag**2)\n",
    "        responses.append((response_real, response_imag, magnitude))\n",
    "    return responses\n",
    "\n",
    "def phase_quantization(responses):\n",
    "    \"\"\"\n",
    "    Quantize the phase of Gabor filter responses into 2-bit binary codes.\n",
    "    :param responses: List of Gabor filter responses (complex values).\n",
    "    :return: Binary feature vector (iris code).\n",
    "    \"\"\"\n",
    "    binary_code = []\n",
    "    for response in responses:\n",
    "        real = response[0]\n",
    "        imag = response[1]\n",
    "        phase = np.arctan2(imag, real)\n",
    "        quantized_phase = ((phase >= 0) & (phase < np.pi/2)) * 0b00 + \\\n",
    "                          ((phase >= np.pi/2) & (phase < np.pi)) * 0b01 + \\\n",
    "                          ((phase >= -np.pi) & (phase < -np.pi/2)) * 0b10 + \\\n",
    "                          ((phase >= -np.pi/2) & (phase < 0)) * 0b11\n",
    "        \n",
    "        # Convert each quantized value to 2 bits (binary representation)\n",
    "        binary_block = np.unpackbits(np.uint8(quantized_phase).reshape(-1, 1), axis=1)[:, -2:]\n",
    "        binary_code.append(binary_block.flatten())\n",
    "  \n",
    "    return np.hstack(binary_code)\n",
    "\n",
    "def FeatureExtraction(image, block_size, scales=1, orientations=4):\n",
    "    \"\"\"\n",
    "    Generate the binary feature vector (iris code) for an input image.\n",
    "    :param image: Normalized iris image.\n",
    "    :param block_size: Size of the blocks for pixel averaging.\n",
    "    :param scales: Number of scales for Gabor filters.\n",
    "    :param orientations: Number of orientations for Gabor filters.\n",
    "    :return: Binary feature vector (iris code).\n",
    "    \"\"\"\n",
    "    # Step 1: Divide the image into blocks and calculate block mean\n",
    "    h, w = image.shape\n",
    "    h_blocks, w_blocks = h // block_size, w // block_size\n",
    "    block_means = np.zeros((h_blocks, w_blocks))\n",
    "    for i in range(h_blocks):\n",
    "        for j in range(w_blocks):\n",
    "            block = image[i * block_size:(i + 1) * block_size, j * block_size:(j + 1) * block_size]\n",
    "            block_means[i, j] = np.mean(block)\n",
    "\n",
    "    # Step 2: Generate Gabor filter bank\n",
    "    filters = gabor_filter_bank(scales=scales, orientations=orientations)\n",
    "    # print(\"First filter: \", filters[0]) \n",
    "\n",
    "    # Step 3: Apply Gabor filters to the block means\n",
    "    responses = apply_gabor_filters(block_means, filters)\n",
    "\n",
    "    # Step 4: Quantize phase to generate binary iris code\n",
    "    iris_code = phase_quantization(responses)\n",
    "\n",
    "    return iris_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shift(code, shift):\n",
    "    \"\"\"\n",
    "    Circularly shift a binary code (list of 0s and 1s).\n",
    "    \n",
    "    Args:\n",
    "        code: List of binary values (e.g., [1, 0, 1, 0, 1]).\n",
    "        shift: Number of positions to shift. Positive for left, negative for right.\n",
    "    \n",
    "    Returns:\n",
    "        Shifted binary code.\n",
    "    \"\"\"\n",
    "    n = len(code)\n",
    "    shift = shift % n  # Handle shifts greater than the length of the code\n",
    "    return code[shift:] + code[:shift]\n",
    "\n",
    "def HammingDistance(code1, code2, mask1=None, mask2=None):\n",
    "    \"\"\"\n",
    "    Compute the Hamming distance between two iris codes.\n",
    "    :param code1: First binary iris code (numpy array).\n",
    "    :param code2: Second binary iris code (numpy array).\n",
    "    :param mask1: Mask for code1 (optional).\n",
    "    :param mask2: Mask for code2 (optional).\n",
    "    :return: Hamming distance.\n",
    "    \"\"\"\n",
    "    if mask1 is not None and mask2 is not None:\n",
    "        # Combine masks and exclude masked bits\n",
    "        combined_mask = mask1 & mask2\n",
    "        differing_bits = np.sum((code1 ^ code2) & ~combined_mask)\n",
    "        total_bits = np.sum(~combined_mask)\n",
    "    else:\n",
    "        # Without masks\n",
    "        differing_bits = np.sum(code1 ^ code2)\n",
    "        total_bits = code1.size\n",
    "    \n",
    "    if total_bits == 0:\n",
    "        return float('inf')  # Handle case where no bits are available for comparison\n",
    "    return differing_bits / total_bits\n",
    "\n",
    "def find_min_hamming_distance(reference_code, query_code):\n",
    "    \"\"\"\n",
    "    Find the minimum Hamming distance by circularly shifting the query code.\n",
    "    \n",
    "    Args:\n",
    "        reference_code: The reference binary code (list of 0s and 1s).\n",
    "        query_code: The query binary code (list of 0s and 1s).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing the minimum Hamming distance and the optimal shift value.\n",
    "    \"\"\"\n",
    "    n = len(query_code)\n",
    "    min_distance = float('inf')\n",
    "    best_shift = 0\n",
    "    \n",
    "    for shift in range(n):\n",
    "        shifted_code = circular_shift(query_code, shift)\n",
    "        reference_code = np.array(reference_code)\n",
    "        shifted_code = np.array(shifted_code)\n",
    "        distance = HammingDistance(reference_code, shifted_code)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_shift = shift\n",
    "    \n",
    "    return min_distance, best_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1:  67 %\n",
      "Test 2:  92 %\n",
      "overall:  79.16666666666666 %\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Define the root path to the dataset\n",
    "rootpath = \"D:/at school/2024.1/Biometric Authentication System/Project/Biometric/IrisRecognition-master/CASIA Iris Image Database (version 1.0)/\"\n",
    "\n",
    "# Record the start time of the process\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# Loop through each subject in the dataset\n",
    "med = 0\n",
    "for i in range(1,3):\n",
    "    # Define paths for training and testing images for the current subject\n",
    "    filespath = rootpath + str(i).zfill(3)\n",
    "    trainpath = filespath + \"/1/\"\n",
    "    testpath = filespath + \"/2/\"\n",
    "\n",
    "    train_iris_code = np.zeros((4, 1024))\n",
    "    test_iris_code = np.zeros((5, 1024))\n",
    "\n",
    "    # Loop through each training image for the current subject\n",
    "    for j in range(1,4):\n",
    "        # Construct the file path for the current training image\n",
    "        irispath = trainpath + str(i).zfill(3) + \"_1_\" + str(j) + \".bmp\"\n",
    "\n",
    "        eye = cv2.imread(irispath, cv2.IMREAD_GRAYSCALE)\n",
    "        iris, pupil = IrisLocalization(eye)\n",
    "        normalized = IrisNormalization(eye, pupil, iris)\n",
    "        # cv2.imwrite('normalized_iris.png', normalized)\n",
    "        # ROI = ImageEnhancement(normalized)\n",
    "        # cv2.imwrite('roi.png', ROI)\n",
    "        block_size = 16\n",
    "        iris_code = FeatureExtraction(normalized, block_size)\n",
    "        train_iris_code[j] = iris_code\n",
    "        # np.savetxt('iris_code_3.txt', iris_code, fmt='%d')\n",
    "\n",
    "    for k in range(1,5):\n",
    "        # Construct the file path for the current training image\n",
    "        irispath = testpath + str(i).zfill(3) + \"_2_\" + str(k) + \".bmp\"\n",
    "\n",
    "        eye = cv2.imread(irispath, cv2.IMREAD_GRAYSCALE)\n",
    "        iris, pupil = IrisLocalization(eye)\n",
    "        normalized = IrisNormalization(eye, pupil, iris)\n",
    "        # cv2.imwrite('normalized_iris.png', normalized)\n",
    "        # ROI = ImageEnhancement(normalized)\n",
    "        # cv2.imwrite('roi.png', ROI)\n",
    "        block_size = 16\n",
    "        iris_code = FeatureExtraction(normalized, block_size)\n",
    "        test_iris_code[k] = iris_code\n",
    "    \n",
    "    count = 0\n",
    "    for j in range(1, 4):\n",
    "        for k in range (1, 5):\n",
    "            train_tmp = train_iris_code[j].astype(int).tolist()\n",
    "            test_tmp = test_iris_code[k].astype(int).tolist()\n",
    "            min_distance, best_shift = find_min_hamming_distance(train_tmp, test_tmp)\n",
    "            if (min_distance <= 0.32):\n",
    "                count += 1\n",
    "            \n",
    "    \n",
    "    print(f\"Test {i}: \", round(count/12 * 100), \"%\")\n",
    "    med = med + count\n",
    "\n",
    "print(\"overall: \", med / 2 /12 * 100, \"%\")\n",
    "\n",
    "# # Example usage\n",
    "# # Load iris codes from text files\n",
    "# iris_code_1 = np.loadtxt('D:/at school/2024.1/Biometric Authentication System/Project/Biometric/iris_code_1.txt', dtype=int)\n",
    "# iris_code_2 = np.loadtxt('D:/at school/2024.1/Biometric Authentication System/Project/Biometric/iris_code_2.txt', dtype=int)\n",
    "# iris_code_3 = np.loadtxt('D:/at school/2024.1/Biometric Authentication System/Project/Biometric/iris_code_3.txt', dtype=int)\n",
    "\n",
    "# # Compute Hamming distance\n",
    "# distance_12 = HammingDistance(iris_code_1, iris_code_2)\n",
    "# print(f\"Hamming Distance 1-2: {distance_12}\")\n",
    "# distance_23 = HammingDistance(iris_code_2, iris_code_3)\n",
    "# print(f\"Hamming Distance 2-3: {distance_23}\")\n",
    "# distance_13 = HammingDistance(iris_code_1, iris_code_3)\n",
    "# print(f\"Hamming Distance 1-3: {distance_13}\")\n",
    "\n",
    "# iris_code_1 = iris_code_1.tolist()\n",
    "# iris_code_2 = iris_code_2.tolist()\n",
    "# iris_code_3 = iris_code_3.tolist()\n",
    "\n",
    "# min_distance, best_shift = find_min_hamming_distance(iris_code_1, iris_code_2)\n",
    "# print(f\"Minimum Hamming Distance 12: {min_distance}\")\n",
    "# print(f\"Optimal Shift 12: {best_shift}\")\n",
    "\n",
    "# min_distance, best_shift = find_min_hamming_distance(iris_code_1, iris_code_3)\n",
    "# print(f\"Minimum Hamming Distance 13: {min_distance}\")\n",
    "# print(f\"Optimal Shift 13: {best_shift}\")\n",
    "\n",
    "# min_distance, best_shift = find_min_hamming_distance(iris_code_2, iris_code_3)\n",
    "# print(f\"Minimum Hamming Distance 23: {min_distance}\")\n",
    "# print(f\"Optimal Shift 23: {best_shift}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Authenticate(iris_code, stored_templates, threshold=0.32):\n",
    "    for template in stored_templates:\n",
    "        distance = HammingDistance(iris_code, template)\n",
    "        if distance < threshold:\n",
    "            return True  # Authentication successful\n",
    "    return False  # Authentication failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucess = Authenticate(iris_code_3, [iris_code_1, iris_code_2])\n",
    "# print(f\"Authentication: {sucess}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
